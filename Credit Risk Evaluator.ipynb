{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from pathlib import Path\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\r\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Categorizing data into X and y\r\n",
    "X_train = train_df.drop(columns=[\"loan_status\"])\r\n",
    "y_train = train_df[\"loan_status\"]\r\n",
    "X_test = test_df.drop(columns=[\"loan_status\"])\r\n",
    "y_test = test_df[\"loan_status\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Converting categorical data into numeric data\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "lbe = LabelEncoder()\r\n",
    "lbe.fit(y_train)\r\n",
    "y_train = lbe.transform(y_train)\r\n",
    "print(y_train)\r\n",
    "lbe.fit(y_test)\r\n",
    "y_test = lbe.transform(y_test)\r\n",
    "print(y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Creating dummies for categorical data and converting it into numerical data\r\n",
    "X_train_dummies = pd.get_dummies(X_train)\r\n",
    "X_test_dummies = pd.get_dummies(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Test dataset has no 0 Value for debt settlement flag\r\n",
    "X_test_dummies.debt_settlement_flag_N.unique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Creating a list of 0 of the same length as the test dataset\r\n",
    "zeros = [0] * len(X_test_dummies[\"debt_settlement_flag_N\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Adding the required missing dummy variables column to the test dataset\r\n",
    "X_test_dummies[\"debt_settlement_flag_Y\"]= zeros"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Confirming that both datasets have the same columns\r\n",
    "print(len(X_test_dummies.columns))\r\n",
    "print(len(X_train_dummies.columns))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "94\n",
      "94\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "PREDICTION\r\n",
    "\r\n",
    "I think that the Logistic Regression Model will perform better than the Random Forest Classifier Model as I believe Logistic regression would perform much better for binary classification."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\r\n",
    "clf = LogisticRegression()\r\n",
    "clf.fit(X_train_dummies, y_train)\r\n",
    "print(clf.score(X_test_dummies, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5253083794130158\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\aarvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Train a Random Forest Classifier model and print the model score\r\n",
    "regr = RandomForestClassifier(n_estimators=500)\r\n",
    "regr.fit(X_train_dummies, y_train)\r\n",
    "print(regr.score(X_test_dummies, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6112292641429179\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Random Forest Classifier performs better on unscaled data contrary to my prediction. This is not surprising as without scaling the data - Logistic Regression Model was doomed to fail as the data is not optimized"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Scaling train and test data\r\n",
    "scaler = StandardScaler()\r\n",
    "scaler.fit(X_train_dummies)\r\n",
    "X_test_dummies_scaled = scaler.transform(X_test_dummies)\r\n",
    "X_train_dummies_scaled = scaler.transform(X_train_dummies)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\r\n",
    "clf.fit(X_train_dummies_scaled, y_train)\r\n",
    "print(clf.score(X_test_dummies_scaled, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7201190982560612\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\aarvi\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\r\n",
    "regr.fit(X_train_dummies_scaled, y_train)\r\n",
    "print(regr.score(X_test_dummies_scaled, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6095278604849\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As my prediction earlier - Logistic Regression perfomed much better on scaled data than on unscaled data. Random Forest Classifier Model had very little change on the score as the scaling does not effect the data for Random Forest Classifier the way it would help optimize it for Logistic Regression."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}